# Production override for docker-compose.yml
# Usage: docker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d

services:
  db:
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-app}
      POSTGRES_USER: ${POSTGRES_USER:-app}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - /data/postgres:/var/lib/postgresql/data
    # Remove port exposure in production
    ports: []
    # Production database settings
    command: >
      postgres
      -c shared_buffers=256MB
      -c effective_cache_size=1GB
      -c maintenance_work_mem=64MB
      -c checkpoint_completion_target=0.9
      -c wal_buffers=16MB
      -c default_statistics_target=100
      -c random_page_cost=1.1
      -c effective_io_concurrency=200
      -c work_mem=4MB
      -c min_wal_size=1GB
      -c max_wal_size=4GB
      -c max_worker_processes=8
      -c max_parallel_workers_per_gather=4
      -c max_parallel_workers=8
      -c max_parallel_maintenance_workers=4

  redis:
    # Remove port exposure in production
    ports: []
    # Production Redis settings
    command: >
      redis-server
      --maxmemory 512mb
      --maxmemory-policy allkeys-lru
      --save 900 1
      --save 300 10
      --save 60 10000
      --appendonly yes
      --appendfsync everysec
    volumes:
      - /data/redis:/data

  minio:
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minio}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
    # Remove port exposure in production
    ports: []
    volumes:
      - /data/minio:/data
    # Production MinIO settings
    command: >
      server /data
      --console-address ":9001"
      --address ":9000"

  api:
    environment:
      DATABASE_URL: postgresql+psycopg://${POSTGRES_USER:-app}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB:-app}
      REDIS_URL: redis://redis:6379/0
      S3_ENDPOINT: http://minio:9000
      S3_ACCESS_KEY: ${MINIO_ROOT_USER:-minio}
      S3_SECRET_KEY: ${MINIO_ROOT_PASSWORD}
      S3_BUCKET: ${S3_BUCKET:-artifacts}
      UVICORN_HOST: 0.0.0.0
      UVICORN_PORT: 8000
      # Production settings
      NODE_ENV: production
      LOG_LEVEL: INFO
      COOKIE_KEY: ${COOKIE_KEY}
      SECRET_KEY: ${SECRET_KEY}
      # Security settings
      ALLOWED_ORIGINS: ${ALLOWED_ORIGINS}
      COOKIE_DOMAIN: ${COOKIE_DOMAIN}
      # Rate limiting
      RATE_LIMIT_PER_MINUTE: ${RATE_LIMIT_PER_MINUTE:-60}
      # Logging
      LOG_RETENTION_DAYS: ${LOG_RETENTION_DAYS:-30}
    # Remove port exposure in production (use reverse proxy)
    ports: []
    # Production API settings
    command: >
      bash -lc "
        alembic upgrade head &&
        uvicorn main:app
        --host 0.0.0.0
        --port 8000
        --workers ${API_WORKERS:-4}
        --access-log
        --no-use-colors
      "
    # Health check for production
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    # Resource limits
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.5'

  worker:
    environment:
      DATABASE_URL: postgresql+psycopg://${POSTGRES_USER:-app}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB:-app}
      REDIS_URL: redis://redis:6379/0
      S3_ENDPOINT: http://minio:9000
      S3_ACCESS_KEY: ${MINIO_ROOT_USER:-minio}
      S3_SECRET_KEY: ${MINIO_ROOT_PASSWORD}
      S3_BUCKET: ${S3_BUCKET:-artifacts}
      # Production settings
      NODE_ENV: production
      LOG_LEVEL: INFO
      COOKIE_KEY: ${COOKIE_KEY}
      # Logging
      LOG_RETENTION_DAYS: ${LOG_RETENTION_DAYS:-30}
    # Production worker settings
    command: >
      celery -A celery_app worker
      --loglevel=info
      --concurrency=${WORKER_CONCURRENCY:-4}
      --max-tasks-per-child=1000
      --time-limit=3600
      --soft-time-limit=3300
    # Resource limits
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '2.0'
        reservations:
          memory: 1G
          cpus: '1.0'
    # Health check
    healthcheck:
      test: ["CMD", "celery", "-A", "celery_app", "inspect", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  scheduler:
    environment:
      DATABASE_URL: postgresql+psycopg://${POSTGRES_USER:-app}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB:-app}
      REDIS_URL: redis://redis:6379/0
      # Production settings
      NODE_ENV: production
      LOG_LEVEL: INFO
    # Resource limits
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'

  beat:
    environment:
      CELERY_BROKER_URL: redis://redis:6379/0
      CELERY_RESULT_BACKEND: redis://redis:6379/0
      DATABASE_URL: postgresql+psycopg://${POSTGRES_USER:-app}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB:-app}
      REDIS_URL: redis://redis:6379/0
      S3_ENDPOINT: http://minio:9000
      S3_ACCESS_KEY: ${MINIO_ROOT_USER:-minio}
      S3_SECRET_KEY: ${MINIO_ROOT_PASSWORD}
      S3_BUCKET: ${S3_BUCKET:-artifacts}
      # Production settings
      NODE_ENV: production
      LOG_LEVEL: INFO
    # Production beat settings
    command: >
      celery -A celery_app beat
      --loglevel=info
      --schedule=/tmp/celerybeat-schedule
      --pidfile=/tmp/celerybeat.pid
    # Resource limits
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.25'
        reservations:
          memory: 128M
          cpus: '0.1'
    # Health check
    healthcheck:
      test: ["CMD", "test", "-f", "/tmp/celerybeat.pid"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 20s

  # Reverse proxy for production
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
      - /var/log/nginx:/var/log/nginx
    depends_on:
      api:
        condition: service_healthy
    restart: unless-stopped
    # Resource limits
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.5'
        reservations:
          memory: 128M
          cpus: '0.25'

  # Monitoring stack (optional)
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - /data/prometheus:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=30d'
      - '--web.enable-lifecycle'
    restart: unless-stopped
    profiles:
      - monitoring

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3001:3000"
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD:-admin}
    volumes:
      - /data/grafana:/var/lib/grafana
    depends_on:
      - prometheus
    restart: unless-stopped
    profiles:
      - monitoring

volumes:
  # Use host volumes for production data persistence
  # These should be mounted to /data on the host
  db_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /data/postgres
  
  redis_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /data/redis
  
  minio_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /data/minio